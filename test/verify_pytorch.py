#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyTorch å®‰è£…æµ‹è¯•è„šæœ¬
æµ‹è¯• PyTorch æ˜¯å¦æ­£ç¡®å®‰è£…å¹¶èƒ½æ­£å¸¸å·¥ä½œ
"""

import sys
import os


def test_pytorch_import():
    """æµ‹è¯• PyTorch å¯¼å…¥"""
    print("=" * 50)
    print("1. æµ‹è¯• PyTorch å¯¼å…¥...")
    try:
        import torch
        import torchvision
        import numpy as np

        print("âœ“ PyTorch å¯¼å…¥æˆåŠŸ")
        return torch
    except ImportError as e:
        print(f"âœ— PyTorch å¯¼å…¥å¤±è´¥: {e}")
        return None


def test_pytorch_version(torch):
    """æµ‹è¯• PyTorch ç‰ˆæœ¬ä¿¡æ¯"""
    print("\n" + "=" * 50)
    print("2. PyTorch ç‰ˆæœ¬ä¿¡æ¯:")
    print(f"   PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"   Python ç‰ˆæœ¬: {sys.version}")

    try:
        import torchvision

        print(f"   TorchVision ç‰ˆæœ¬: {torchvision.__version__}")
    except:
        print("   TorchVision: æœªå®‰è£…")


def test_basic_operations(torch):
    """æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ"""
    print("\n" + "=" * 50)
    print("3. æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ...")

    try:
        # åˆ›å»ºå¼ é‡
        x = torch.randn(3, 4)
        y = torch.randn(4, 5)

        # çŸ©é˜µä¹˜æ³•
        z = torch.mm(x, y)
        print(f"âœ“ å¼ é‡åˆ›å»ºå’ŒçŸ©é˜µä¹˜æ³•æˆåŠŸ")
        print(f"   x.shape = {x.shape}, y.shape = {y.shape}, z.shape = {z.shape}")

        # æ¢¯åº¦è®¡ç®—
        x.requires_grad_(True)
        loss = x.sum()
        loss.backward()
        print(f"âœ“ æ¢¯åº¦è®¡ç®—æˆåŠŸ")
        print(f"   x.grad.shape = {x.grad.shape}")

        return True
    except Exception as e:
        print(f"âœ— åŸºæœ¬æ“ä½œå¤±è´¥: {e}")
        return False


def test_cuda_availability(torch):
    """æµ‹è¯• CUDA å¯ç”¨æ€§"""
    print("\n" + "=" * 50)
    print("4. æµ‹è¯• CUDA æ”¯æŒ...")

    if torch.cuda.is_available():
        print("âœ“ CUDA å¯ç”¨")
        print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPU æ•°é‡: {torch.cuda.device_count()}")

        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            print(f"   GPU {i}: {gpu_name}")

        # æµ‹è¯• GPU è®¡ç®—
        try:
            device = torch.device("cuda:0")
            x = torch.randn(1000, 1000).to(device)
            y = torch.randn(1000, 1000).to(device)
            z = torch.mm(x, y)
            print("âœ“ GPU è®¡ç®—æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âœ— GPU è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
            return False
    else:
        print("âš  CUDA ä¸å¯ç”¨ (è¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœæ‚¨æ²¡æœ‰ NVIDIA GPU)")
        return False


def test_simple_model(torch):
    """æµ‹è¯•ç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å‹"""
    print("\n" + "=" * 50)
    print("5. æµ‹è¯•ç®€å•ç¥ç»ç½‘ç»œ...")

    try:
        import torch.nn as nn
        import torch.optim as optim

        # åˆ›å»ºç®€å•çš„çº¿æ€§æ¨¡å‹
        model = nn.Sequential(nn.Linear(10, 5), nn.ReLU(), nn.Linear(5, 1))

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        x = torch.randn(100, 10)
        y = torch.randn(100, 1)

        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01)

        # è®­ç»ƒå‡ æ­¥
        for epoch in range(5):
            optimizer.zero_grad()
            outputs = model(x)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

        print("âœ“ ç®€å•ç¥ç»ç½‘ç»œè®­ç»ƒæˆåŠŸ")
        print(f"   æœ€ç»ˆæŸå¤±: {loss.item():.4f}")
        return True

    except Exception as e:
        print(f"âœ— ç¥ç»ç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("6. æµ‹è¯•æ•°æ®åŠ è½½...")

    try:
        from torch.utils.data import DataLoader, TensorDataset
        import torch

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
        x = torch.randn(100, 10)
        y = torch.randn(100, 1)
        dataset = TensorDataset(x, y)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch_x, batch_y in dataloader:
            print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"   æ‰¹æ¬¡å¤§å°: {batch_x.shape[0]}")
            break

        return True

    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("PyTorch å®‰è£…æµ‹è¯•å¼€å§‹")
    print("=" * 50)

    # æµ‹è¯•å¯¼å…¥
    torch = test_pytorch_import()
    if torch is None:
        print("\nâŒ PyTorch æœªæ­£ç¡®å®‰è£…ï¼Œè¯·é‡æ–°å®‰è£…")
        return False

    # æµ‹è¯•ç‰ˆæœ¬
    test_pytorch_version(torch)

    # æµ‹è¯•åŸºæœ¬æ“ä½œ
    if not test_basic_operations(torch):
        print("\nâŒ åŸºæœ¬æ“ä½œæµ‹è¯•å¤±è´¥")
        return False

    # æµ‹è¯• CUDA
    cuda_available = test_cuda_availability(torch)

    # æµ‹è¯•æ¨¡å‹
    if not test_simple_model(torch):
        print("\nâŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False

    # æµ‹è¯•æ•°æ®åŠ è½½
    if not test_data_loading():
        print("\nâŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥")
        return False

    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€»ç»“:")
    print("âœ“ PyTorch åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
    print("âœ“ å¼ é‡æ“ä½œæ­£å¸¸")
    print("âœ“ ç¥ç»ç½‘ç»œåŠŸèƒ½æ­£å¸¸")
    print("âœ“ æ•°æ®åŠ è½½åŠŸèƒ½æ­£å¸¸")
    if cuda_available:
        print("âœ“ CUDA GPU åŠ é€Ÿå¯ç”¨")
    else:
        print("âš  CUDA ä¸å¯ç”¨ (CPU æ¨¡å¼)")

    print("\nğŸ‰ PyTorch å®‰è£…æµ‹è¯•å®Œæˆï¼æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
